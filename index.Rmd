---
title: "PracticalMachineLearning"
author: "Kevin Ohkura"
date: "Saturday, March 11, 2017"
output: html_document
---

#Overview

The goal of this project is to build a model that predicts the manner in which a weight lifting exercise is done based on data collected from accelerometers attached to various parts of the body of the person doing the exercises.

#Data Preprocessing

The data is split into a [training set](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv) and [test set](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv) which can be downloaded from their respective links.

```{r}
training <- read.csv("pml-training.csv", na.strings=c("NA", "", "#DIV/0!"))
testing <- read.csv("pml-testing.csv", na.strings=c("NA", "", "#DIV/0!"))
dimtrain <- dim(training)
```

The training set contains `r dimtrain[1]` observations and `r dimtrain[2]` variables. The variable "classe" will serve as labels that we want to predict for the test set. According to the [source of the data](http://groupware.les.inf.puc-rio.br/har), "Six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E)." Using accelerometer data, we want to predict which of these classes the observed action belongs to.

The training data contains variables that are made up completely of missing data. Some variables represent information that have nothing to do with the accelerometer measurements (such as the name of the participant or the timestamp). Both types of variables will not be considered by the model and should be removed.

```{r}
#remove all NA variables
training <-training[,colSums(is.na(training)) == 0]

#remove variables irrelevant to accelerometer measurements
training <- training[,-c(1:7)]
```

#Building the Model

Random forests tend to be one of the most accurate machine learning algorithms. Given the nature of the problem, predicting labels from a bunch of different features, the random forest algorithm seems to be a good solution. It will automatically choose the best features out of the big pool of variables, and decision trees make a lot of sense for a label-prediction problem.

**5-fold cross validation** will be used to estimate the accuracy of the algorithm without touching the test set. **Out of sample error** can be estimated as 1-accuracy. Thus, the out-of-sample error can also be estimated by cross validation.

```{r, message=FALSE}
library(caret)

set.seed(777)
modFit <- train(classe~., data=training, method="rf", ntree=100, trControl=trainControl(method="cv", number=5))

modFit$finalModel
```

As seen above, the out of bag error rate is 0.52%. The confusion matrix shows low classification error rates across the board. Thus, we can expect the model to do quite well on the test set as well.

#Predicting Test Set Labels

Finally, we use the model to predict the test set labels.

```{r}
predict(modFit, testing)
```

